{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Coronal_training_evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gPXg-HvdqKZ",
        "colab_type": "text"
      },
      "source": [
        "The first 3 Cells to Download the data and extracting it in google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlath2hEVtCM",
        "colab_type": "code",
        "outputId": "2a45b6d9-94fa-49cb-adc5-44ee4ba739f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "!wget http://download.cs.stanford.edu/deep/MRNet-v1.0.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-19 11:49:07--  http://download.cs.stanford.edu/deep/MRNet-v1.0.zip\n",
            "Resolving download.cs.stanford.edu (download.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to download.cs.stanford.edu (download.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6087523606 (5.7G) [application/zip]\n",
            "Saving to: ‘MRNet-v1.0.zip’\n",
            "\n",
            "MRNet-v1.0.zip      100%[===================>]   5.67G  17.5MB/s    in 5m 17s  \n",
            "\n",
            "2019-05-19 11:54:24 (18.3 MB/s) - ‘MRNet-v1.0.zip’ saved [6087523606/6087523606]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHtcXRq8Xv8J",
        "colab_type": "code",
        "outputId": "b7877a7f-5daf-4c8f-f471-5f7fc14018b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM2PZLMN62Jw",
        "colab_type": "code",
        "outputId": "72c52e49-0c64-4c46-ea87-96f1e414a5fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "!unzip -qq \"/content/MRNet-v1.0.zip\" -d \"/content/gdrive/My Drive/MRNet Challenge/\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "warning [/content/MRNet-v1.0.zip]:  4294967296 extra bytes at beginning or within zipfile\n",
            "  (attempting to process anyway)\n",
            "file #1:  bad zipfile offset (local header sig):  4294967296\n",
            "  (attempting to re-compensate)\n",
            "file #2547:  bad zipfile offset (local header sig):  1353202\n",
            "  (attempting to re-compensate)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVoiVKEzeOeX",
        "colab_type": "text"
      },
      "source": [
        "# Data Set Exploaration\n",
        "This Cell to learn how to read an image from the data set .\n",
        "\n",
        "you will find the images is saved as numpy array ,each image have a lot of different  copies may be 44 or 38 not a constant number .\n",
        "The data set consist of videos not images .\n",
        "\n",
        "to make it clear \n",
        "we will have a model with input of (number of photos in video*3*256*256)\n",
        "why 3 ?i don't know \n",
        "we will make three different models\n",
        "the csv files are the labels of the data \n",
        "\n",
        "note : cv2.imshow() function is not working just use cv2_imshow() \n",
        "the difference is the \".\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RvlVYm__8CO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd \n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Read data from file 'filename.csv' \n",
        "# (in the same directory that your python process is based)\n",
        "# Control delimiters, rows, column names with read_csv (see later) \n",
        "data1 = pd.read_csv(\"/content/gdrive/My Drive/MRNet Challenge/MRNet-v1.0/train-abnormal.csv\") \n",
        "print(data1.shape)\n",
        "\n",
        "data2 = pd.read_csv(\"/content/gdrive/My Drive/MRNet Challenge/MRNet-v1.0/train-acl.csv\") \n",
        "print(data2.shape)\n",
        "\n",
        "data3 = pd.read_csv(\"/content/gdrive/My Drive/MRNet Challenge/MRNet-v1.0/train-meniscus.csv\") \n",
        "print(data3.shape)\n",
        "# print(data[0,0])\n",
        "# print(type(data[0,0]))\n",
        "a=np.load(\"/content/gdrive/My Drive/MRNet Challenge/MRNet-v1.0/train/coronal/0002.npy\")\n",
        "# print(a)\n",
        "print(a.shape)\n",
        "cv2_imshow(a[0])\n",
        "cv2_imshow(a[1])\n",
        "cv2_imshow(a[2])\n",
        "cv2_imshow(a[3])\n",
        "cv2_imshow(a[4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCPQEmfUgAVv",
        "colab_type": "text"
      },
      "source": [
        "# Reading the whole dataset\n",
        "**be careful don't run this cell again it will take around 15 mins** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO9q8J7YMUhp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HuiOjaqgAjh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "paths =[ \"/content/gdrive/My Drive/MRNet Challenge/MRNet-v1.0/train/coronal/\"\n",
        "        ,\"/content/gdrive/My Drive/MRNet Challenge/MRNet-v1.0/train/axial/\",\"/content/gdrive/My Drive/MRNet Challenge/MRNet-v1.0/train/sagittal/\"]\n",
        "all_data = []\n",
        "for path in paths:\n",
        "  directory=[]\n",
        "  for r, d, f in os.walk(path):\n",
        "      for file in f:\n",
        "          if '.npy' in file:\n",
        "              directory.append(os.path.join(r, file))\n",
        "  all_data.append(directory)\n",
        "\n",
        "# for f in files:\n",
        "#     print(f)\n",
        "\n",
        "\n",
        "\n",
        "def to_rgb(img,i):\n",
        "    img = cv2.resize(img, (256,256), interpolation = cv2.INTER_AREA) \n",
        "#     print(img.shape)\n",
        "    img_rgb = np.asarray(np.dstack((img, img, img)), dtype=np.uint8)\n",
        "    if i==0:\n",
        "      print(img.shape)\n",
        "      cv2_imshow(img)\n",
        "      print(img_rgb.shape)\n",
        "      cv2_imshow(img_rgb)\n",
        "#     img_rgb.shape\n",
        "#     img_rgb=np.swapaxes(img_rgb,0,2)\n",
        "\n",
        "#     print(img_rgb.shape)\n",
        "    return img_rgb\n",
        "\n",
        "# coronal=np.zeros(shape=(16649,256,256,3),dtype='uint8')\n",
        "# coronalList=[]\n",
        "sizes=[]\n",
        "axialList=[]\n",
        "k=0\n",
        "# sagittal=[]\n",
        "for i in range(len(all_data[1])):\n",
        "  print(i)\n",
        "  a=np.load(all_data[1][i])\n",
        "  f,j,k=a.shape\n",
        "  sizes.append(f//2)\n",
        "  for j in range(f//2):\n",
        "    b=to_rgb(a[j],i+j)\n",
        "    axialList.append(b)\n",
        "#     coronal[k]=b\n",
        "#     if i+j==0:\n",
        "#       cv2_imshow(coronal[k])\n",
        "\n",
        "  \n",
        "    k+=1\n",
        "    \n",
        "axial=np.asarray(axialList,dtype='uint8')\n",
        "axialList=None\n",
        "print(axial.shape)\n",
        "    \n",
        "print(axial.shape)\n",
        "cv2_imshow(axial[0])\n",
        "\n",
        "#   axial.append(np.load(all_data[1][i]))\n",
        "#   sagittal.append(np.load(all_data[2][i]))\n",
        "  \n",
        "#   dataset[i,0]=a[0]\n",
        "#   dataset[i,1]=b[0]\n",
        "#   dataset[i,2]=c[0]\n",
        "#   d=np.hstack((a[0],b[0],c[0]))\n",
        "#   cv2_imshow(d)\n",
        "#   e=np.hstack((dataset[i,0],dataset[i,1],dataset[i,2]))\n",
        "print(\"coronal read\")\n",
        "#   cv2_imshow(e)\n",
        "#   cv2_imshow(dataset[i,0])\n",
        "#   cv2_imshow(dataset[i,])\n",
        "\n",
        "\n",
        "#   print(a.shape)\n",
        "#   print(b.shape)\n",
        "\n",
        "#   print(c.shape)\n",
        "#   print(\"-------------------------\")\n",
        "#   print(\"-------------------------\")\n",
        "#   print(\"-------------------------\")\n",
        "#   print(\"-------------------------\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2LFE80rbdPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(coronal[0].shape)\n",
        "cv2_imshow(coronal[0])\n",
        "print(coronal[0])\n",
        "a=coronal[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOm_ObJPhbmI",
        "colab_type": "text"
      },
      "source": [
        "#getting labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0XVRQtk3Bcr",
        "colab_type": "code",
        "outputId": "9ef522e4-a29d-4783-b7e4-42e189c353e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import pandas as pd\n",
        "# model.compile(loss=keras.losses.categorical_crossentropy, optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "data1 = pd.read_csv(\"/content/gdrive/My Drive/MRNet Challenge/MRNet-v1.0/train-abnormal.csv\") \n",
        "print(data1.shape)\n",
        "# print(data1.columns)\n",
        "# print(data1['1'])\n",
        "y=np.array(data1[\"1\"])\n",
        "print(\"---------------------------------\")\n",
        "y=np.hstack(('1',y))\n",
        "# print(y)\n",
        "Y_train=[]\n",
        "for i in range(len(sizes)):\n",
        "  for j in range(sizes[i]):\n",
        "    Y_train.append(y[i])\n",
        " \n",
        "Y_train=np.asarray(Y_train)\n",
        "print(Y_train.shape)\n",
        "# print(data1[:][1])\n",
        "# labels=data1[1]\n",
        "# print(labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1129, 2)\n",
            "---------------------------------\n",
            "(16649,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcalH4-Rt6BC",
        "colab_type": "code",
        "outputId": "25e364ed-3d22-4438-9af9-8e987e1a3b9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "Y_train2=np.zeros(shape=(16649,2))\n",
        "for i in range(len(Y_train)):\n",
        "  if Y_train[i] == '1':\n",
        "    Y_train2[i][1]=1\n",
        "  elif Y_train[i] == '0':\n",
        "    Y_train2[i][0]=1\n",
        "#Y_train\n",
        "Y_train2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QAynjXn5bp4",
        "colab_type": "code",
        "outputId": "f7978600-9f18-40d2-c08b-5de4b24255a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#print(Y_train2)\n",
        "ones =0\n",
        "zer =0\n",
        "for j in range(2):\n",
        "  for i in range(len(Y_train2)):\n",
        "  \n",
        "    if Y_train2[i][j] == 1:\n",
        "        ones+=1\n",
        "    else:\n",
        "        zer+=1\n",
        "  print(ones,\" \",zer)  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3157   13492\n",
            "16649   16649\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7P92u5Fhq1o",
        "colab_type": "text"
      },
      "source": [
        "# Start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQ6ZSKOL3fHi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath=\"/content/gdrive/My Drive/MRNet Challenge/MRNet Weights\"\n",
        "X_train=np.array(coronal[0])\n",
        "j=10000;\n",
        "for i in range(len(coronal)):\n",
        "#   print(len(coronal[i]))\n",
        "  if len(coronal[i])<j:\n",
        "    j=len(coronal[i])\n",
        "    print(j)\n",
        "#    print(len(coronal[i]))\n",
        "# history=model.fit(X_train,\n",
        "#     Y_train,\n",
        "#     batch_size=1024,\n",
        "#     epochs=100,\n",
        "#     verbose=2,\n",
        "#      validation_split=0.05,\n",
        "#     callbacks = [\n",
        "#         keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='auto'),\n",
        "#         keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
        "#     ])\n",
        "# we re-load the best weights once training is finished\n",
        "# model.load_weights(filepath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlyViPRBBVjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras.applications.xception.Xception(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuWUfkroBaSd",
        "colab_type": "text"
      },
      "source": [
        "** until now the first problem that the every video doesn't have the same number of frames , the first solution is to take the minimum number of frames and neglect the rest **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1gCM_2NnEMI",
        "colab_type": "text"
      },
      "source": [
        "# ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZdUGAPanFzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Imports\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from urllib.request import urlopen,urlretrieve\n",
        "from PIL import Image\n",
        "from tqdm import tqdm_notebook\n",
        "%matplotlib inline\n",
        "from sklearn.utils import shuffle\n",
        "import cv2\n",
        "\n",
        "from keras.models import load_model\n",
        "from sklearn.datasets import load_files   \n",
        "from keras.utils import np_utils\n",
        "from glob import glob\n",
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator \n",
        "from keras import optimizers\n",
        "from keras.models import Sequential,Model,load_model\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D\n",
        "from keras.callbacks import TensorBoard,ReduceLROnPlateau,ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyX8bybaSxmD",
        "colab_type": "text"
      },
      "source": [
        "# With ImageNet Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk5Twi4WnLGB",
        "colab_type": "code",
        "outputId": "d8ad3ebe-03f6-422f-9cea-1ab6d65a3557",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Pretrained model\n",
        "img_height,img_width = 256,256 \n",
        "num_classes = 2\n",
        "#If imagenet weights are being loaded, \n",
        "#input must have a static square shape (one of (128, 128), (160, 160), (192, 192), or (224, 224))\n",
        "WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5', WEIGHTS_PATH_NO_TOP, cache_subdir='models', md5_hash='a268eb855778b3df3c7506639542a6af')\n",
        "base_model = applications.resnet50.ResNet50(weights= 'imagenet', include_top=False, input_shape= (img_height,img_width,3))\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.7)(x)\n",
        "predictions = Dense(num_classes, activation= 'softmax')(x)\n",
        "model2 = Model(inputs = base_model.input, outputs = predictions)\n",
        "#model2.load_weights(weights_path,by_name=True)\n",
        "from keras.optimizers import SGD, Adam\n",
        "# sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
        "adam = Adam(lr=0.0001)\n",
        "model2.compile(optimizer= adam, loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KInBhz_QnXV8",
        "colab_type": "code",
        "outputId": "df8114e0-b785-4478-db0f-980bc7723ccd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#Fitting data\n",
        "\n",
        "#1st - Coronal with Abnormal labels\n",
        "#images = np.reshape(coronal,(len(coronal),256,256,3))\n",
        "model2.fit(coronal, Y_train2, epochs = 5, batch_size = 64)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "16649/16649 [==============================] - 277s 17ms/step - loss: 0.5368 - acc: 0.7890\n",
            "Epoch 2/5\n",
            "16649/16649 [==============================] - 230s 14ms/step - loss: 0.3728 - acc: 0.8420\n",
            "Epoch 3/5\n",
            "16649/16649 [==============================] - 230s 14ms/step - loss: 0.1915 - acc: 0.9239\n",
            "Epoch 4/5\n",
            "16649/16649 [==============================] - 230s 14ms/step - loss: 0.0932 - acc: 0.9646\n",
            "Epoch 5/5\n",
            "16649/16649 [==============================] - 230s 14ms/step - loss: 0.0660 - acc: 0.9757\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efcc410c128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE2rMK18SgLY",
        "colab_type": "text"
      },
      "source": [
        "# Trying without loading ImageNet Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNQF6YAwSjMm",
        "colab_type": "code",
        "outputId": "352fe062-e098-4dd2-8252-4db8d0301d60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Pretrained model\n",
        "img_height,img_width = 256,256 \n",
        "num_classes = 2\n",
        "#WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "#weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5', WEIGHTS_PATH_NO_TOP, cache_subdir='models', md5_hash='a268eb855778b3df3c7506639542a6af')\n",
        "#If imagenet weights are being loaded, \n",
        "#input must have a static square shape (one of (128, 128), (160, 160), (192, 192), or (224, 224))\n",
        "base_model = applications.resnet50.ResNet50(weights=None, include_top=False, input_shape= (img_height,img_width,3))\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.4)(x)\n",
        "predictions = Dense(num_classes, activation= 'softmax')(x)\n",
        "model3 = Model(inputs = base_model.input, outputs = predictions)\n",
        "#model3.load_weights(weights_path,by_name=True)\n",
        "from keras.optimizers import SGD, Adam\n",
        "# sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
        "adam = Adam(lr=0.0001)\n",
        "model3.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLcJWJqabcY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVnQqHjvSsa6",
        "colab_type": "code",
        "outputId": "c26811f7-2ac4-4c56-bd09-2bf54042a917",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#1st - Coronal with Abnormal labels\n",
        "#images = np.reshape(coronal,(len(coronal),256,256,3))\n",
        "model3.fit(coronal, Y_train2, epochs = 5, batch_size = 64)\n",
        "model3.train_on_batch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "16649/16649 [==============================] - 274s 16ms/step - loss: 0.4927 - acc: 0.7968\n",
            "Epoch 2/5\n",
            "16649/16649 [==============================] - 231s 14ms/step - loss: 0.2537 - acc: 0.8960\n",
            "Epoch 3/5\n",
            "16649/16649 [==============================] - 231s 14ms/step - loss: 0.1148 - acc: 0.9572\n",
            "Epoch 4/5\n",
            "16649/16649 [==============================] - 230s 14ms/step - loss: 0.0513 - acc: 0.9823\n",
            "Epoch 5/5\n",
            "16649/16649 [==============================] - 230s 14ms/step - loss: 0.0363 - acc: 0.9876\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efcbe1c7978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObyUwLrgqI4i",
        "colab_type": "text"
      },
      "source": [
        "# New ResNet Implemented from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w46jAEx3qNs_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You will learn how to build very deep convolutional networks, using Residual Networks (ResNets)\n",
        "# In theory, very deep networks can represent very complex functions; but in practice, they are hard to train. Residual Networks, introduced by He et al., allow you to train much deeper networks than were previously practically feasible.\n",
        "\n",
        "# Let's import packages\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "#from resnets_utils import *\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)\n",
        "\n",
        "# Identity block\n",
        "\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block as defined in Figure 3\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    \n",
        "    # Second component of main path \n",
        "    X = Conv2D(filters = F2, kernel_size=(f,f), strides = (1,1), padding='same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size=(1,1), strides = (1,1), padding=\"valid\", name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X,X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    \n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pvMT4xSsS4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The convolutional block\n",
        "# GRADED FUNCTION: convolutional_block\n",
        "\n",
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block as defined in Figure 4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(filters = F1, kernel_size= (1, 1), strides = (s,s),padding=\"valid\", name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "\n",
        "    # Second component of main path \n",
        "    X = Conv2D(filters = F2, kernel_size=(f,f), strides=(1,1), name = conv_name_base + '2b', padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name= bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size=(1,1), strides = (1,1), name= conv_name_base + '2c',padding=\"valid\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(filters = F3, kernel_size= (1,1), strides=(s,s), name=conv_name_base + '1', padding=\"valid\", kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base+'1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    \n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39uOkLs4stJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ResNet 50\n",
        "\n",
        "def ResNet50(input_shape = (256, 256, 3), classes = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(256, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "\n",
        "    # Stage 3\n",
        "    X = convolutional_block(X, f=3, filters = [128,128,512], stage = 3, block='a', s=2)\n",
        "    X = identity_block(X, 3, filters = [128,128,512],stage=3, block='b')\n",
        "    X = identity_block(X, 3, filters = [128,128,512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, filters = [128,128,512], stage =3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f=3, filters = [256,256,1024],stage=4, block='a', s=2)\n",
        "    X = identity_block(X, 3, filters = [256,256,1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, filters = [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, filters= [256,256,1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, filters=[256,256,1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, filters=[256,256,1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f=3, filters=[256,256,2048], stage=5,block='a', s=3)\n",
        "    X = identity_block(X, 3, filters=[256,256,2048], stage=5, block='b')\n",
        "    X = identity_block(X,3, filters=[256,256,2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D((2,2), name='avg_pool')(X)\n",
        "    \n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "    #WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "    #weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5', WEIGHTS_PATH_NO_TOP, cache_subdir='models', md5_hash='a268eb855778b3df3c7506639542a6af')\n",
        "    #model.load_weights()\n",
        "    #model.load_weights(weights_path,by_name=True)\n",
        "    \n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHQakmVdsx-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run the following code to build the model's graph. If your implementation is not correct you will know it by checking your accuracy when running model.fit(...) below.\n",
        "model = ResNet50(input_shape = (256, 256, 3), classes = 2)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysDRaG_3tFga",
        "colab_type": "code",
        "outputId": "c9f5ff62-928c-42c4-f379-4382a586fd29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "model.fit(coronal, Y_train2, epochs = 5, batch_size = 32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "16649/16649 [==============================] - 243s 15ms/step - loss: 0.6644 - acc: 0.7888\n",
            "Epoch 2/5\n",
            "16649/16649 [==============================] - 241s 14ms/step - loss: 0.5949 - acc: 0.8029\n",
            "Epoch 3/5\n",
            "16649/16649 [==============================] - 241s 14ms/step - loss: 0.5654 - acc: 0.8035\n",
            "Epoch 4/5\n",
            "16649/16649 [==============================] - 241s 14ms/step - loss: 0.5353 - acc: 0.8050\n",
            "Epoch 5/5\n",
            "16649/16649 [==============================] - 241s 14ms/step - loss: 0.5229 - acc: 0.8045\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efcf8b07550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VZVtv0NttSF",
        "colab_type": "code",
        "outputId": "0041ba74-ce39-476b-cd83-fcb4dce8905d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.shape(Y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16649,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8R-bvrPSyZuR",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNOAgO8CycyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Prepare the test set\n",
        "paths =[ \"/content/gdrive/My Drive/MRNet Challenge/MRNet-v1.0/valid/coronal/\"\n",
        "        ,\"/content/gdrive/My Drive/MRNet Challenge/MRNet-v1.0/valid/axial/\",\"/content/gdrive/My Drive/MRNet Challenge/MRNet-v1.0/valid/sagittal/\"]\n",
        "all_data2 = []\n",
        "for path in paths:\n",
        "  directory=[]\n",
        "  for r, d, f in os.walk(path):\n",
        "      for file in f:\n",
        "          if '.npy' in file:\n",
        "              directory.append(os.path.join(r, file))\n",
        "  all_data2.append(directory)\n",
        "\n",
        "#for j in range(len(all_data[0])):\n",
        "  \n",
        "#coronal_test=np.zeros(shape=(16649,256,256,3),dtype='uint8')\n",
        "coronalList=[]\n",
        "sizes=[]\n",
        "# axial=[]\n",
        "k=0\n",
        "# sagittal=[]\n",
        "for i in range(len(all_data2[0])):\n",
        "  print(i)\n",
        "  a=np.load(all_data2[0][i])\n",
        "  f,j,k=a.shape\n",
        "  sizes.append(f//2)\n",
        "  for j in range(f//2):\n",
        "    b=to_rgb(a[j],i+j)\n",
        "    coronalList.append(b)\n",
        "  \n",
        "    k+=1\n",
        "    \n",
        "coronal_test=np.asarray(coronalList,dtype='uint8')\n",
        "coronalList=None\n",
        "print(coronal_test.shape)\n",
        "    \n",
        "print(coronal_test.shape)\n",
        "cv2_imshow(coronal_test[0])\n",
        "\n",
        "print(\"Done valid reading.\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6g4LiCuJz3KV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Test labels\n",
        "import pandas as pd\n",
        "\n",
        "data1_test = pd.read_csv(\"/content/gdrive/My Drive/MRNet Challenge/MRNet-v1.0/valid-abnormal.csv\") \n",
        "print(data1_test.shape)\n",
        "# print(data1.columns)\n",
        "# print(data1['1'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGViGdB-4jjq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(data1_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIJ4tQlm4M0H",
        "colab_type": "code",
        "outputId": "4e50ef69-ea38-444e-e8dd-a02582a18812",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "y_test=np.array(data1_test[\"0\"])\n",
        "#print(y_test)\n",
        "\n",
        "print(\"---------------------------------\")\n",
        "y_test=np.hstack(('1',y_test))\n",
        "# print(y)\n",
        "Y_test=[]\n",
        "for i in range(len(sizes)):\n",
        "  for j in range(sizes[i]):\n",
        "    Y_test.append(y_test[i])\n",
        " \n",
        "Y_test=np.asarray(Y_test)\n",
        "print(Y_test.shape)\n",
        "#rint(Y_test)\n",
        "# print(data1[:][1])\n",
        "# labels=data1[1]\n",
        "# print(labels)\n",
        "Y_test2=np.zeros(shape=(1749,2))\n",
        "for i in range(1749):\n",
        "  if Y_test[i] == '1':\n",
        "    Y_test2[i][1]=1\n",
        "  elif Y_test2[i] == '0':\n",
        "    Y_test2[i][0]=1\n",
        "#Y_train\n",
        "Y_test2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------------\n",
            "(1749,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ld3h3esOoSuE",
        "colab_type": "text"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHPW7ArpoCAf",
        "colab_type": "code",
        "outputId": "e36db7f2-6419-43df-990d-480ae14283fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "preds = model.evaluate(coronal_test, Y_test2)\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1749/1749 [==============================] - 9s 5ms/step\n",
            "Loss = 0.3811340511373413\n",
            "Test Accuracy = 0.8979416809605489\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqSDG7BGybWI",
        "colab_type": "code",
        "outputId": "284067cc-0985-478e-b386-2dccbb3721dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "preds = model2.evaluate(coronal_test, Y_test2)\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1749/1749 [==============================] - 29s 16ms/step\n",
            "Loss = 0.8142469329892601\n",
            "Test Accuracy = 0.8413379074438018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-GMy-ozmK_v",
        "colab_type": "code",
        "outputId": "f2460f73-c847-4634-d2fa-f173d6487aef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "preds = model3.evaluate(coronal_test, Y_test2)\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1749/1749 [==============================] - 9s 5ms/step\n",
            "Loss = 0.24812371320830814\n",
            "Test Accuracy = 0.7444253860029785\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEcgGQrjsXSr",
        "colab_type": "text"
      },
      "source": [
        "# Begin the combined training ( One model will be trained several times once per series )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gh1L_3upuXWp",
        "colab_type": "code",
        "outputId": "9f6454cf-a000-40b6-d312-5e82b5ade197",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Pretrained model\n",
        "img_height,img_width = 256,256 \n",
        "num_classes = 2\n",
        "#If imagenet weights are being loaded, \n",
        "#input must have a static square shape (one of (128, 128), (160, 160), (192, 192), or (224, 224))\n",
        "WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5', WEIGHTS_PATH_NO_TOP, cache_subdir='models', md5_hash='a268eb855778b3df3c7506639542a6af')\n",
        "base_model = applications.resnet50.ResNet50(weights= 'imagenet', include_top=False, input_shape= (img_height,img_width,3))\n",
        "#weights= 'imagenet'\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.7)(x)\n",
        "predictions = Dense(num_classes, activation= 'softmax')(x)\n",
        "\n",
        "#sagital_model.load_weights(weights_path,by_name=True)\n",
        "from keras.optimizers import SGD, Adam\n",
        "# sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
        "adam = Adam(lr=0.0001)\n",
        "sagital_model = Model(inputs = base_model.input, outputs = predictions)\n",
        "sagital_model.compile(optimizer= adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "coronal_model = Model(inputs = base_model.input, outputs = predictions)\n",
        "coronal_model.compile(optimizer= adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "axial_model = Model(inputs = base_model.input, outputs = predictions)\n",
        "axial_model.compile(optimizer= adam, loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}